# ============================================================
# AZURE ML MANAGED ONLINE DEPLOYMENT CONFIGURATION
# ============================================================
# This file defines how your model is deployed to the endpoint.
# A deployment specifies:
# - Which model version to use
# - What compute resources to allocate
# - How many instances to run
# - Traffic allocation
#
# Key Concepts:
# - One endpoint can have multiple deployments (blue/green deployment)
# - Each deployment can use different model versions or configurations
# - Traffic is split between deployments based on percentage allocation
# ============================================================

# Schema version for Azure ML deployment configuration
$schema: https://azuremlschemas.azureedge.net/latest/managedOnlineDeployment.schema.json

# Name of this specific deployment
# You can have multiple deployments (e.g., "blue", "green") under one endpoint
name: diabetes-deploy-blue

# Which endpoint this deployment belongs to
# Must match the name in endpoint.yml
endpoint_name: diabetes-prediction-endpoint

# Model to deploy
# Format: azureml:<model-name>@latest
# The "@latest" means it will use the most recently registered version
# When you register a model, this will automatically point to it
model: azureml:diabetes-model@latest

# Scoring script for MLflow model inference
# This script handles the HTTP requests and calls the model
code_configuration:
  code: . # Upload files from src/ directory
  scoring_script: main.py # Main scoring script for the model

# Environment (runtime) for the deployment
# This specifies the Docker image with Python, libraries, and dependencies
# Using the same environment as training ensures consistency
# This includes scikit-learn 0.24 which matches our training script
environment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest

# Compute instance type for running the deployment
# IMPORTANT: Azure ML automatically creates this compute for you!
# You do NOT need to manually create compute instances in Azure ML Studio
# This is different from training jobs which use pre-created compute clusters
# https://learn.microsoft.com/en-us/azure/machine-learning/reference-managed-online-endpoints-vm-sku-list?view=azureml-api-2
instance_type: Standard_E4s_v3

# Number of instances to run
# Start with 1 instance to minimize quota usage
instance_count: 1

# Resource requests and limits (optional but recommended for production)
# This helps with cost management and prevents resource exhaustion
request_settings:
  request_timeout_ms: 10000  # Timeout for each request (10 seconds)
  max_concurrent_requests_per_instance: 1  # How many requests can run simultaneously per instance
  max_queue_wait_ms: 1000  # How long to wait in queue before rejecting (1 second)

# Liveness probe - checks if the deployment is responsive
# If this fails, the instance will be restarted
liveness_probe:
  initial_delay: 10  # Wait 10 seconds after startup before checking
  period: 10  # Check every 10 seconds
  timeout: 2  # Each probe times out after 2 seconds
  success_threshold: 1  # 1 successful probe means healthy
  failure_threshold: 3  # 3 failed probes triggers restart

# Readiness probe - checks if the deployment is ready to receive traffic
# If this fails, traffic won't be sent to this instance
readiness_probe:
  initial_delay: 10  # Wait 10 seconds after startup before checking
  period: 10  # Check every 10 seconds
  timeout: 2  # Each probe times out after 2 seconds
  success_threshold: 1  # 1 successful probe means ready
  failure_threshold: 3  # 3 failed probes means not ready

# Tags for organization
tags:
  deployment_type: "blue"
  model_version: "latest"


